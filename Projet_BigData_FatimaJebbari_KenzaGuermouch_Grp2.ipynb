{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHE-GKJSj1uZ"
      },
      "source": [
        " Kenza Guermouch 932356421 \n",
        " Fatima Jebbari 932355441\n",
        " \n",
        " \n",
        " Importation des bibliothèques et initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7POihAAPZY2"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, DateType, DoubleType, LongType, StringType\n",
        "from pyspark.sql.functions import col, count, when, lag, datediff, avg, stddev, min, max, corr\n",
        "from pyspark.sql.functions import year, month, weekofyear\n",
        "from pyspark.sql.window import Window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoJDfhFXBpub"
      },
      "outputs": [],
      "source": [
        "# Initialiser Spark\n",
        "spark = SparkSession.builder.appName(\"StockDataAnalysis\").getOrCreate()\n",
        "\n",
        "# Fonction pour lire les données\n",
        "\n",
        "def download_stock_data(tickers, start_date, end_date):\n",
        "    \"\"\"Télécharge les données des actions via yfinance et les convertit en DataFrame Spark.\"\"\"\n",
        "    data = {}\n",
        "    schema = StructType([\n",
        "        StructField(\"Date\", DateType(), True),\n",
        "        StructField(\"Open\", DoubleType(), True),\n",
        "        StructField(\"High\", DoubleType(), True),\n",
        "        StructField(\"Low\", DoubleType(), True),\n",
        "        StructField(\"Close\", DoubleType(), True),\n",
        "        StructField(\"Adj Close\", DoubleType(), True),\n",
        "        StructField(\"Volume\", LongType(), True),\n",
        "        StructField(\"Ticker\", StringType(), True)\n",
        "    ])\n",
        "    for ticker in tickers:\n",
        "        df = yf.download(ticker, start=start_date, end=end_date)\n",
        "        if df.empty:\n",
        "            print(f\"Aucune donnée pour {ticker}\")\n",
        "            continue\n",
        "        df.reset_index(inplace=True)\n",
        "        df['Ticker'] = ticker\n",
        "        spark_df = spark.createDataFrame(df, schema=schema)\n",
        "        data[ticker] = spark_df.dropna()\n",
        "    return data\n",
        "\n",
        "# Télécharger les données\n",
        "start_date = \"2020-01-01\"\n",
        "end_date = \"2023-01-01\"\n",
        "tickers = [\"AAPL\", \"MSFT\", \"GOOGL\"]\n",
        "stock_data = download_stock_data(tickers, start_date, end_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcLDrCd0F9Lg"
      },
      "source": [
        "### Analyse des Données des Actions\n",
        "\n",
        "Ce script permet d'analyser les données historiques des actions en utilisant Apache Spark et yfinance. Les fonctions implémentées permettent d'explorer, de comprendre et d'extraire des insights utiles des données. Voici un résumé des fonctionnalités principales :\n",
        "\n",
        "1. **Exploration des Données :**\n",
        "   - `show_first_last_rows`: Affiche les 40 premières et dernières lignes de chaque DataFrame pour avoir un aperçu des données.\n",
        "   - `get_observation_count`: Compte le nombre total d'observations dans le DataFrame.\n",
        "   - `deduce_periodicity`: Identifie la périodicité des points de données en calculant la différence entre les dates successives.\n",
        "   - `descriptive_statistics`: Affiche les statistiques descriptives (moyenne, écart-type, min, max) pour toutes les colonnes.\n",
        "   - `count_missing_values`: Comptabilise les valeurs manquantes pour chaque colonne.\n",
        "\n",
        "2. **Corrélation :**\n",
        "   - `calculate_correlation_all_pairs`: Calcule la corrélation entre toutes les paires d'actions pour une colonne donnée (par exemple, le prix de clôture).\n",
        "\n",
        "3. **Calcul des Variations :**\n",
        "   - `calculate_variations`: Ajoute des colonnes pour les variations quotidiennes et mensuelles des prix.\n",
        "\n",
        "4. **Identification des Meilleures Actions :**\n",
        "   - `best_stock_by_period`: Identifie l'action avec le meilleur rendement moyen pour une période donnée (mois ou année).\n",
        "\n",
        "5. **Synthèse des Insights :**\n",
        "   - `summarize_insights`: Compile tous les insights calculés (exploration, corrélations, variations) pour chaque action dans une structure lisible.\n",
        "\n",
        "6. **Visualisation :**\n",
        "   - `plot_variations`: Génère des graphiques pour visualiser les variations quotidiennes et mensuelles des prix des actions.\n",
        "\n",
        "Le script est conçu pour fonctionner avec plusieurs tickers (par exemple, AAPL, MSFT, GOOGL) et fournit des visualisations interactives pour mieux comprendre les tendances et les performances des actions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k55nu2JQagP"
      },
      "outputs": [],
      "source": [
        "# Fonction pour afficher les 40 premières et dernières lignes\n",
        "\n",
        "def show_first_last_rows(spark_df):\n",
        "    print(\"Premières 40 lignes :\")\n",
        "    spark_df.show(40)\n",
        "    print(\"Dernières 40 lignes :\")\n",
        "    spark_df.orderBy(col(\"Date\").desc()).show(40)\n",
        "\n",
        "# Fonction pour obtenir le nombre d'observations\n",
        "\n",
        "def get_observation_count(spark_df):\n",
        "    count = spark_df.count()\n",
        "    print(f\"Nombre total d'observations : {count}\")\n",
        "\n",
        "# Fonction pour déduire la période entre les points de données\n",
        "\n",
        "def deduce_periodicity(spark_df):\n",
        "    window_spec = Window.orderBy(\"Date\")\n",
        "    spark_df = spark_df.withColumn(\"Difference\", datediff(col(\"Date\"), lag(\"Date\", 1).over(window_spec)))\n",
        "    periodicity = spark_df.select(\"Difference\").distinct().collect()\n",
        "    print(\"Périodes distinctes entre les points de données :\", [row[\"Difference\"] for row in periodicity])\n",
        "\n",
        "# Fonction pour calculer les statistiques descriptives\n",
        "\n",
        "def descriptive_statistics(spark_df):\n",
        "    print(\"Statistiques descriptives :\")\n",
        "    spark_df.describe().show()\n",
        "\n",
        "# Fonction pour compter les valeurs manquantes\n",
        "\n",
        "def count_missing_values(spark_df):\n",
        "    print(\"Valeurs manquantes par colonne :\")\n",
        "    missing = spark_df.select([count(when(col(c).isNull(), c)).alias(c) for c in spark_df.columns])\n",
        "    missing.show()\n",
        "\n",
        "# Fonction pour calculer la corrélation entre colonnes\n",
        "\n",
        "def calculate_correlation(spark_df, col1, col2):\n",
        "    correlation = spark_df.corr(col1, col2)\n",
        "    print(f\"Corrélation entre {col1} et {col2} : {correlation}\")\n",
        "\n",
        "# Appliquer les fonctions sur les données téléchargées\n",
        "for ticker, df in stock_data.items():\n",
        "    print(f\"\\nAnalyse pour {ticker} :\")\n",
        "    show_first_last_rows(df)\n",
        "    get_observation_count(df)\n",
        "    deduce_periodicity(df)\n",
        "    descriptive_statistics(df)\n",
        "    count_missing_values(df)\n",
        "    calculate_correlation(df, \"Open\", \"Close\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M01HDn6zGPWg"
      },
      "source": [
        "### Analyse des Prix et Rendements des Actions\n",
        "\n",
        "Le code ci-dessus effectue une analyse approfondie des prix et des rendements des actions pour chaque ticker dans le jeu de données. Voici les principales étapes :\n",
        "\n",
        "1. **Calcul des Moyennes des Prix :**\n",
        "   - La fonction `calculate_average_prices` calcule les moyennes des prix d'ouverture et de clôture pour différentes périodes : annuelle, mensuelle et hebdomadaire. Les résultats sont affichés dans des tableaux pour chaque période.\n",
        "\n",
        "2. **Calcul des Rendements Quotidiens :**\n",
        "   - La fonction `calculate_daily_return` calcule le rendement quotidien pour chaque date en comparant le prix de clôture du jour courant avec celui du jour précédent. Ces rendements sont ajoutés sous forme d'une nouvelle colonne `Daily_Return`.\n",
        "\n",
        "3. **Identification du Rendement Quotidien Maximum :**\n",
        "   - La fonction `highest_daily_return` identifie la date, le ticker, et le rendement quotidien maximum pour l'ensemble des données.\n",
        "\n",
        "4. **Calcul des Moyennes des Rendements :**\n",
        "   - La fonction `calculate_average_returns` calcule les moyennes des rendements quotidiens pour différentes périodes : annuelle, mensuelle et hebdomadaire. Ces moyennes permettent d'identifier les tendances globales des rendements pour chaque action.\n",
        "\n",
        "5. **Application des Fonctions :**\n",
        "   - Pour chaque ticker, les fonctions ci-dessus sont appliquées en séquence afin de produire des insights détaillés sur les variations des prix et des rendements.\n",
        "\n",
        "Ce code est utile pour comprendre les performances historiques des actions sur différentes périodes et identifier les moments de forte volatilité ou de rendements élevés.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU_hOL9oQmDt"
      },
      "outputs": [],
      "source": [
        "def calculate_average_prices(spark_df):\n",
        "    print(\"Moyennes des prix d'ouverture et de clôture par période :\")\n",
        "    spark_df = spark_df.withColumn(\"Year\", year(col(\"Date\")))\n",
        "    spark_df = spark_df.withColumn(\"Month\", month(col(\"Date\")))\n",
        "    spark_df = spark_df.withColumn(\"Week\", weekofyear(col(\"Date\")))\n",
        "    yearly_avg = spark_df.groupBy(\"Year\").agg(avg(\"Open\").alias(\"Avg_Open_Year\"), avg(\"Close\").alias(\"Avg_Close_Year\"))\n",
        "    monthly_avg = spark_df.groupBy(\"Year\", \"Month\").agg(avg(\"Open\").alias(\"Avg_Open_Month\"), avg(\"Close\").alias(\"Avg_Close_Month\"))\n",
        "    weekly_avg = spark_df.groupBy(\"Year\", \"Week\").agg(avg(\"Open\").alias(\"Avg_Open_Week\"), avg(\"Close\").alias(\"Avg_Close_Week\"))\n",
        "    yearly_avg.show()\n",
        "    monthly_avg.show()\n",
        "    weekly_avg.show()\n",
        "\n",
        "\n",
        "#Calcul des rendements quotidiens\n",
        "def calculate_daily_return(spark_df):\n",
        "    window_spec = Window.orderBy(\"Date\")\n",
        "    spark_df = spark_df.withColumn(\n",
        "        \"Daily_Return\",\n",
        "        (col(\"Close\") - lag(\"Close\", 1).over(window_spec)) / lag(\"Close\", 1).over(window_spec)\n",
        "    )\n",
        "    spark_df.select(\"Date\", \"Ticker\", \"Daily_Return\").show(10)\n",
        "    return spark_df\n",
        "\n",
        "def highest_daily_return(spark_df):\n",
        "    max_return = spark_df.orderBy(col(\"Daily_Return\").desc()).select(\"Date\", \"Ticker\", \"Daily_Return\").first()\n",
        "    print(f\"Action avec le rendement quotidien le plus élevé : {max_return}\")\n",
        "\n",
        "def calculate_average_returns(spark_df):\n",
        "    spark_df = spark_df.withColumn(\"Year\", year(col(\"Date\")))\n",
        "    spark_df = spark_df.withColumn(\"Month\", month(col(\"Date\")))\n",
        "    spark_df = spark_df.withColumn(\"Week\", weekofyear(col(\"Date\")))\n",
        "    yearly_avg_return = spark_df.groupBy(\"Year\").agg(avg(\"Daily_Return\").alias(\"Avg_Daily_Return_Year\"))\n",
        "    monthly_avg_return = spark_df.groupBy(\"Year\", \"Month\").agg(avg(\"Daily_Return\").alias(\"Avg_Daily_Return_Month\"))\n",
        "    weekly_avg_return = spark_df.groupBy(\"Year\", \"Week\").agg(avg(\"Daily_Return\").alias(\"Avg_Daily_Return_Week\"))\n",
        "    yearly_avg_return.show()\n",
        "    monthly_avg_return.show()\n",
        "    weekly_avg_return.show()\n",
        "\n",
        "\n",
        "for ticker, df in stock_data.items():\n",
        "    print(f\"\\nAnalyse pour {ticker} :\")\n",
        "    calculate_average_prices(df)\n",
        "    df = calculate_daily_return(df)\n",
        "    highest_daily_return(df)\n",
        "    calculate_average_returns(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVE_hiP0EcbL"
      },
      "outputs": [],
      "source": [
        "# Fonction pour calculer la moyenne mobile\n",
        "\n",
        "def calculate_moving_average(spark_df, column, period):\n",
        "    \"\"\"Ajoute une colonne de moyenne mobile au DataFrame Spark.\"\"\"\n",
        "    window_spec = Window.orderBy(\"Date\").rowsBetween(-(period - 1), 0)\n",
        "    spark_df = spark_df.withColumn(f\"{column}_MA_{period}\", avg(col(column)).over(window_spec))\n",
        "    return spark_df\n",
        "\n",
        "# Fonction pour calculer le rendement par période (semaine, mois, année)\n",
        "\n",
        "def calculate_periodic_return(spark_df, period):\n",
        "    \"\"\"Calcule le rendement pour différentes périodes.\"\"\"\n",
        "    if period == \"week\":\n",
        "        spark_df = spark_df.withColumn(\"Week\", weekofyear(col(\"Date\")))\n",
        "        returns = spark_df.groupBy(\"Week\").agg(avg(\"Daily_Return\").alias(\"Avg_Weekly_Return\"))\n",
        "    elif period == \"month\":\n",
        "        spark_df = spark_df.withColumn(\"Month\", month(col(\"Date\")))\n",
        "        returns = spark_df.groupBy(\"Month\").agg(avg(\"Daily_Return\").alias(\"Avg_Monthly_Return\"))\n",
        "    elif period == \"year\":\n",
        "        spark_df = spark_df.withColumn(\"Year\", year(col(\"Date\")))\n",
        "        returns = spark_df.groupBy(\"Year\").agg(avg(\"Daily_Return\").alias(\"Avg_Yearly_Return\"))\n",
        "    else:\n",
        "        raise ValueError(\"Invalid period. Choose from 'week', 'month', 'year'.\")\n",
        "    returns.show()\n",
        "\n",
        "# Fonction pour identifier l'action avec le meilleur rendement pour une période donnée\n",
        "\n",
        "def best_stock_by_period(stock_data, period):\n",
        "    \"\"\"Identifie l'action avec le meilleur rendement moyen dans une période donnée.\"\"\"\n",
        "    best_stocks = {}\n",
        "    for ticker, spark_df in stock_data.items():\n",
        "        spark_df = calculate_daily_return(spark_df)\n",
        "        spark_df = spark_df.withColumn(\"Period\", col(\"Date\"))\n",
        "        avg_return = spark_df.groupBy(\"Ticker\").agg(avg(\"Daily_Return\").alias(\"Avg_Return\"))\n",
        "        best_stocks[ticker] = avg_return.orderBy(col(\"Avg_Return\").desc()).first()\n",
        "    for ticker, result in best_stocks.items():\n",
        "        print(f\"Meilleure action pour {ticker} dans la période : {result}\")\n",
        "\n",
        "# Fonction pour visualiser les prix moyens d'ouverture et de clôture\n",
        "\n",
        "def plot_average_prices(spark_df, ticker):\n",
        "    pandas_df = spark_df.select(\"Year\", \"Month\", \"Week\", \"Open\", \"Close\").toPandas()\n",
        "    pandas_df = pandas_df.groupby([\"Year\", \"Month\"]).mean().reset_index()\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(pandas_df.index, pandas_df[\"Open\"], label=\"Prix Moyen Ouverture\", marker=\"o\")\n",
        "    plt.plot(pandas_df.index, pandas_df[\"Close\"], label=\"Prix Moyen Clôture\", marker=\"o\")\n",
        "    plt.title(f\"Prix Moyens d'Ouverture et de Clôture - {ticker}\")\n",
        "    plt.xlabel(\"Temps (Mois)\")\n",
        "    plt.ylabel(\"Prix\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Fonction pour visualiser les rendements quotidiens\n",
        "\n",
        "def plot_daily_return(spark_df, ticker):\n",
        "    pandas_df = spark_df.select(\"Date\", \"Daily_Return\").toPandas()\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(pandas_df[\"Date\"], pandas_df[\"Daily_Return\"], label=\"Rendement Quotidien\", marker=\".\")\n",
        "    plt.title(f\"Rendement Quotidien - {ticker}\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Rendement Quotidien\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKtTPTK-EUqq"
      },
      "outputs": [],
      "source": [
        "# Ajouter les colonnes nécessaires pour la visualisation\n",
        "def add_time_columns(spark_df):\n",
        "    \"\"\"Ajoute les colonnes Year, Month et Week au DataFrame.\"\"\"\n",
        "    spark_df = spark_df.withColumn(\"Year\", year(col(\"Date\")))\n",
        "    spark_df = spark_df.withColumn(\"Month\", month(col(\"Date\")))\n",
        "    spark_df = spark_df.withColumn(\"Week\", weekofyear(col(\"Date\")))\n",
        "    return spark_df\n",
        "\n",
        "# Visualisation\n",
        "for ticker, df in stock_data.items():\n",
        "    print(f\"\\nVisualisation pour {ticker} :\")\n",
        "    df = add_time_columns(df)  # Ajouter les colonnes Year, Month, Week\n",
        "    df = calculate_moving_average(df, \"Close\", 5)\n",
        "    df = calculate_daily_return(df)\n",
        "    plot_average_prices(df, ticker)\n",
        "    plot_daily_return(df, ticker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YANrvs2Hajq"
      },
      "source": [
        "### Analyse et Interprétation des Graphiques\n",
        "\n",
        "1. **Rendement Quotidien pour AAPL :**\n",
        "   Ce graphique montre les variations quotidiennes du rendement de l'action AAPL entre 2020 et 2023. Nous pouvons observer des pics de rendement importants, ce qui reflète une volatilité élevée sur certaines périodes. Ces rendements quotidiens aident à comprendre la performance et le risque de cette action sur des horizons courts.\n",
        "\n",
        "2. **Prix Moyens d'Ouverture et de Clôture pour MSFT :**\n",
        "   Ce graphique illustre les tendances des prix moyens d'ouverture et de clôture de l'action MSFT sur une période mensuelle. Les deux courbes sont étroitement alignées, indiquant que les prix d'ouverture et de clôture évoluent de manière similaire. Une croissance constante est visible sur certaines périodes, suivie d'une stabilisation ou d'un déclin.\n",
        "\n",
        "3. **Rendement Quotidien pour MSFT :**\n",
        "   Le rendement quotidien de MSFT montre une volatilité relativement stable avec quelques fluctuations importantes. Ces informations sont cruciales pour identifier les jours de rendements exceptionnels et évaluer les risques associés à cette action.\n",
        "\n",
        "4. **Prix Moyens d'Ouverture et de Clôture pour GOOGL :**\n",
        "   Ce graphique représente les tendances des prix moyens d'ouverture et de clôture de GOOGL sur une base mensuelle. Une croissance significative est observée sur certaines périodes, suivie de corrections de marché. La cohérence entre les courbes d'ouverture et de clôture suggère une stabilité relative dans les variations journalières.\n",
        "\n",
        "5. **Rendement Quotidien pour GOOGL :**\n",
        "   Le graphique du rendement quotidien de GOOGL met en évidence des périodes de grande volatilité, souvent associées à des événements de marché ou des annonces spécifiques à l'entreprise. Ces informations sont utiles pour les investisseurs cherchant à comprendre les comportements journaliers de l'action.\n",
        "\n",
        "Ces analyses visuelles complètent les calculs statistiques pour fournir une vue d'ensemble claire de la performance des actions et de leurs comportements respectifs sur des périodes données.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mp2ZMj2JFYmT"
      },
      "outputs": [],
      "source": [
        "def calculate_variations(spark_df):\n",
        "    \"\"\"Ajoute des colonnes pour les variations jour à jour et mois à mois.\"\"\"\n",
        "    window_spec = Window.orderBy(\"Date\")\n",
        "    spark_df = spark_df.withColumn(\"Daily_Change\", col(\"Close\") - lag(\"Close\", 1).over(window_spec))\n",
        "    spark_df = spark_df.withColumn(\"Monthly_Change\", col(\"Close\") - lag(\"Close\", 30).over(window_spec))\n",
        "    return spark_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVKY5Y4eFcZA"
      },
      "outputs": [],
      "source": [
        "def plot_variations(spark_df, ticker):\n",
        "    pandas_df = spark_df.select(\"Date\", \"Daily_Change\", \"Monthly_Change\").toPandas()\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(pandas_df[\"Date\"], pandas_df[\"Daily_Change\"], label=\"Variation Quotidienne\", marker=\".\")\n",
        "    plt.plot(pandas_df[\"Date\"], pandas_df[\"Monthly_Change\"], label=\"Variation Mensuelle\", marker=\".\")\n",
        "    plt.title(f\"Variations des Prix - {ticker}\")\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Variation\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zotfZD2LFfB6"
      },
      "outputs": [],
      "source": [
        "# Visualisation et synthèse\n",
        "for ticker, df in stock_data.items():\n",
        "    print(f\"\\nVisualisation pour {ticker} :\")\n",
        "    df = calculate_variations(df)\n",
        "    plot_variations(df, ticker)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8q7E_XwHuTl"
      },
      "source": [
        "### Variations des Prix pour AAPL, MSFT et GOOGL\n",
        "\n",
        "Le graphique présente les variations quotidiennes et mensuelles des prix des actions AAPL, MSFT et GOOGL entre 2020 et 2023. Les variations quotidiennes (en bleu) restent relativement stables avec des fluctuations modérées, reflétant les mouvements réguliers des marchés financiers. En revanche, les variations mensuelles (en orange) montrent des pics significatifs, indiquant des tendances plus larges influencées par des événements majeurs, des annonces économiques ou des performances spécifiques à chaque entreprise. Ces graphiques permettent d'observer la volatilité à court terme et les changements plus marqués sur des périodes plus longues, offrant ainsi une vision complète des comportements des actions pour les investisseurs cherchant à comprendre leur performance et leur risque.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMsnjNtxDW6E"
      },
      "outputs": [],
      "source": [
        "# Fonction pour calculer la corrélation entre toutes les paires d'actions\n",
        "\n",
        "def calculate_correlation_all_pairs(stock_data, column):\n",
        "    \"\"\"Calcule la corrélation entre toutes les paires d'actions pour une colonne donnée.\"\"\"\n",
        "    tickers = list(stock_data.keys())\n",
        "    for i in range(len(tickers)):\n",
        "        for j in range(i + 1, len(tickers)):\n",
        "            stock1 = tickers[i]\n",
        "            stock2 = tickers[j]\n",
        "            df1 = stock_data[stock1].select(\"Date\", col(column).alias(f\"{column}_{stock1}\"))\n",
        "            df2 = stock_data[stock2].select(\"Date\", col(column).alias(f\"{column}_{stock2}\"))\n",
        "            joined_df = df1.join(df2, on=\"Date\")\n",
        "            correlation = joined_df.stat.corr(f\"{column}_{stock1}\", f\"{column}_{stock2}\")\n",
        "            print(f\"Corrélation entre {stock1} et {stock2} sur la colonne {column} : {correlation}\")\n",
        "\n",
        "# Exemple d'utilisation : Calcul de la corrélation entre toutes les paires d'actions pour la colonne 'Close'\n",
        "calculate_correlation_all_pairs(stock_data, \"Close\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qga7bTdNDXM8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_correlation_matrix(stock_data, column):\n",
        "    \"\"\"Trace une matrice de corrélation entre les colonnes des actions.\"\"\"\n",
        "    tickers = list(stock_data.keys())\n",
        "    data_for_corr = []\n",
        "\n",
        "    for ticker in tickers:\n",
        "        df = stock_data[ticker].select(\"Date\", col(column).alias(f\"{ticker}_{column}\")).toPandas()\n",
        "        df.set_index(\"Date\", inplace=True)\n",
        "        data_for_corr.append(df)\n",
        "\n",
        "    # Concaténer les colonnes des prix pour créer une matrice\n",
        "    merged_data = pd.concat(data_for_corr, axis=1).dropna()\n",
        "\n",
        "    # Calculer la matrice de corrélation\n",
        "    correlation_matrix = merged_data.corr()\n",
        "\n",
        "    # Visualiser la matrice de corrélation\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "    plt.title(f\"Matrice de corrélation pour {column}\")\n",
        "    plt.show()\n",
        "\n",
        "# Exemple d'utilisation\n",
        "plot_correlation_matrix(stock_data, \"Close\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpx0ao7MH426"
      },
      "source": [
        "### Key Insights from Stock Data Analysis\n",
        "\n",
        "1. **Highest Average Closing Price**: Among the analyzed stocks, the stock with the highest average closing price demonstrates strong and consistent performance, making it attractive for long-term investment.\n",
        "2. **Highest Daily Volatility**: Identifying the most volatile stock provides insight into potential short-term trading opportunities and associated risks.\n",
        "3. **Correlation Between Stocks**: The correlation matrix reveals how the selected stocks move together, helping in portfolio diversification and risk management.\n",
        "4. **Best Performing Periods**: By analyzing returns over different periods, the most profitable times for investment in each stock are identified.\n",
        "5. **Most Consistent Stock**: The stock with the least variability in returns showcases stability, suitable for risk-averse investors.\n",
        "6. **Highest Traded Stock**: The stock with the highest average trading volume reflects strong market interest and liquidity.\n",
        "7. **Highest Monthly Returns**: Pinpointing the months with the best performance assists in identifying seasonal trends and optimal entry points.\n",
        "8. **Longest Growth Streak**: Observing the longest consecutive growth streak highlights consistent upward momentum in a stock's performance.\n",
        "\n",
        "These insights collectively aid in understanding stock behavior, supporting better investment decisions, and offering a comprehensive view of the selected stock data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AaI1ibJDiX-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ensure Daily_Return is calculated for all stocks before insights\n",
        "def calculate_daily_return_all(stock_data):\n",
        "    \"\"\"Adds the Daily_Return column to all DataFrames in stock_data.\"\"\"\n",
        "    for ticker, df in stock_data.items():\n",
        "        window_spec = Window.orderBy(\"Date\")\n",
        "        stock_data[ticker] = df.withColumn(\n",
        "            \"Daily_Return\",\n",
        "            (col(\"Close\") - lag(\"Close\", 1).over(window_spec)) / lag(\"Close\", 1).over(window_spec)\n",
        "        )\n",
        "    print(\"Daily_Return column added to all stock DataFrames.\")\n",
        "\n",
        "# Call this function before performing insights\n",
        "calculate_daily_return_all(stock_data)\n",
        "\n",
        "# Insight 1: Stock with the highest average closing price\n",
        "def highest_avg_close(stock_data):\n",
        "    max_avg = None\n",
        "    averages = []\n",
        "    for ticker, df in stock_data.items():\n",
        "        avg_close = df.select(avg(\"Close\").alias(\"Avg_Close\")).collect()[0][\"Avg_Close\"]\n",
        "        averages.append((ticker, avg_close))\n",
        "        if not max_avg or avg_close > max_avg[1]:\n",
        "            max_avg = (ticker, avg_close)\n",
        "    print(f\"L'action avec le prix moyen de clôture le plus élevé est {max_avg[0]} avec {max_avg[1]:.2f}\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    tickers, avg_closes = zip(*averages)\n",
        "    plt.bar(tickers, avg_closes, color='blue', alpha=0.7)\n",
        "    plt.title(\"Prix moyen de clôture pour chaque action\")\n",
        "    plt.ylabel(\"Prix moyen de clôture\")\n",
        "    plt.xlabel(\"Action\")\n",
        "    plt.show()\n",
        "    return max_avg\n",
        "\n",
        "# Insight 2: Stock with the highest daily return variability\n",
        "def highest_volatility(stock_data):\n",
        "    max_vol = None\n",
        "    volatilities = []\n",
        "    for ticker, df in stock_data.items():\n",
        "        std_dev = df.select(stddev(\"Daily_Return\").alias(\"Std_Dev\")).collect()[0][\"Std_Dev\"]\n",
        "        volatilities.append((ticker, std_dev))\n",
        "        if not max_vol or std_dev > max_vol[1]:\n",
        "            max_vol = (ticker, std_dev)\n",
        "    print(f\"L'action avec la plus grande volatilité quotidienne est {max_vol[0]} avec une std. dev. de {max_vol[1]:.4f}\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    tickers, std_devs = zip(*volatilities)\n",
        "    plt.bar(tickers, std_devs, color='orange', alpha=0.7)\n",
        "    plt.title(\"Volatilité quotidienne (écart-type des rendements) pour chaque action\")\n",
        "    plt.ylabel(\"Volatilité quotidienne (std dev)\")\n",
        "    plt.xlabel(\"Action\")\n",
        "    plt.show()\n",
        "    return max_vol\n",
        "\n",
        "# Insight 3: Correlation matrix across all stocks\n",
        "def calculate_correlation_matrix(stock_data, column):\n",
        "    tickers = list(stock_data.keys())\n",
        "    data_for_corr = []\n",
        "\n",
        "    for ticker in tickers:\n",
        "        df = stock_data[ticker].select(\"Date\", col(column).alias(f\"{ticker}_{column}\")).toPandas()\n",
        "        df.set_index(\"Date\", inplace=True)\n",
        "        data_for_corr.append(df)\n",
        "\n",
        "    merged_data = pd.concat(data_for_corr, axis=1).dropna()\n",
        "    correlation_matrix = merged_data.corr()\n",
        "    print(\"Matrice de corrélation entre les stocks:\")\n",
        "    print(correlation_matrix)\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "    plt.title(f\"Matrice de corrélation pour {column}\")\n",
        "    plt.show()\n",
        "\n",
        "    return correlation_matrix\n",
        "\n",
        "# Insight 4: Periods with highest overall returns\n",
        "def best_period(stock_data):\n",
        "    best_periods = {}\n",
        "    for ticker, df in stock_data.items():\n",
        "        df = df.withColumn(\"Year\", year(col(\"Date\")))\n",
        "        yearly_return = df.groupBy(\"Year\").agg(avg(\"Daily_Return\").alias(\"Yearly_Return\"))\n",
        "        best_periods[ticker] = yearly_return.orderBy(col(\"Yearly_Return\").desc()).first()\n",
        "    for ticker, period in best_periods.items():\n",
        "        print(f\"Pour {ticker}, la meilleure année est {period['Year']} avec un rendement annuel moyen de {period['Yearly_Return']:.4f}\")\n",
        "    return best_periods\n",
        "\n",
        "# Insight 5: Most consistent stock (lowest variability in returns)\n",
        "def most_consistent_stock(stock_data):\n",
        "    min_vol = None\n",
        "    consistencies = []\n",
        "    for ticker, df in stock_data.items():\n",
        "        std_dev = df.select(stddev(\"Daily_Return\").alias(\"Std_Dev\")).collect()[0][\"Std_Dev\"]\n",
        "        consistencies.append((ticker, std_dev))\n",
        "        if not min_vol or std_dev < min_vol[1]:\n",
        "            min_vol = (ticker, std_dev)\n",
        "    print(f\"L'action la plus constante est {min_vol[0]} avec une std. dev. de {min_vol[1]:.4f}\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    tickers, std_devs = zip(*consistencies)\n",
        "    plt.bar(tickers, std_devs, color='green', alpha=0.7)\n",
        "    plt.title(\"Constance des actions (écart-type des rendements)\")\n",
        "    plt.ylabel(\"Volatilité quotidienne (std dev)\")\n",
        "    plt.xlabel(\"Action\")\n",
        "    plt.show()\n",
        "    return min_vol\n",
        "\n",
        "# Insight 6: Stock with highest total volume traded\n",
        "def highest_traded_stock(stock_data):\n",
        "    max_volume = None\n",
        "    volumes = []\n",
        "    for ticker, df in stock_data.items():\n",
        "        total_volume = df.select(avg(\"Volume\").alias(\"Total_Volume\")).collect()[0][\"Total_Volume\"]\n",
        "        volumes.append((ticker, total_volume))\n",
        "        if not max_volume or total_volume > max_volume[1]:\n",
        "            max_volume = (ticker, total_volume)\n",
        "    print(f\"L'action la plus échangée est {max_volume[0]} avec un volume moyen de {max_volume[1]:.2f}\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    tickers, avg_volumes = zip(*volumes)\n",
        "    plt.bar(tickers, avg_volumes, color='purple', alpha=0.7)\n",
        "    plt.title(\"Volume moyen échangé pour chaque action\")\n",
        "    plt.ylabel(\"Volume moyen\")\n",
        "    plt.xlabel(\"Action\")\n",
        "    plt.show()\n",
        "    return max_volume\n",
        "\n",
        "# Apply and summarize insights\n",
        "print(\"\\n--- Calculating Insights with Visualizations ---\")\n",
        "highest_avg_close(stock_data)\n",
        "highest_volatility(stock_data)\n",
        "correlation_matrix = calculate_correlation_matrix(stock_data, \"Close\")\n",
        "best_period(stock_data)\n",
        "most_consistent_stock(stock_data)\n",
        "highest_traded_stock(stock_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl1296x7JtBf"
      },
      "source": [
        "### Analyse des graphiques\n",
        "\n",
        "1. **Matrice de corrélation pour les prix de clôture des actions :**  \n",
        "   Ce graphique présente une matrice de corrélation entre les prix de clôture des actions AAPL, MSFT et GOOGL. Les corrélations sont toutes très élevées, montrant des valeurs allant de **0.86 à 0.97**, ce qui indique que les actions évoluent de manière similaire, probablement influencées par des tendances communes du marché.\n",
        "\n",
        "2. **Volatilité quotidienne (écart-type des rendements) :**  \n",
        "   Ce graphique en barres montre l'écart-type des rendements quotidiens pour chaque action. AAPL présente la volatilité la plus élevée (**0.020**), suivie de GOOGL et MSFT qui sont légèrement inférieurs. Cela indique qu'AAPL est la plus volatile des trois actions, impliquant des fluctuations de prix plus importantes au quotidien.\n",
        "\n",
        "3. **Volume moyen échangé pour chaque action :**  \n",
        "   Ce graphique met en évidence le volume moyen des transactions pour AAPL, MSFT et GOOGL. AAPL domine largement avec un volume moyen supérieur à **100 millions**, tandis que MSFT et GOOGL sont beaucoup plus bas. Cela suggère qu'AAPL est l'action la plus activement échangée, ce qui pourrait être un indicateur de sa popularité parmi les investisseurs.\n",
        "\n",
        "4. **Prix moyen de clôture pour chaque action :**  \n",
        "   Ce graphique en barres illustre le prix moyen de clôture pour chaque action sur la période étudiée. MSFT a le prix moyen de clôture le plus élevé (environ **250 USD**), suivi par AAPL et GOOGL. Cela reflète la perception de la valeur marchande de ces actions sur la période donnée.\n",
        "\n",
        "5. **Volatilité quotidienne (récapitulation avec une échelle différente) :**  \n",
        "   Une autre visualisation des écarts-types des rendements pour réitérer que toutes les actions affichent des niveaux de volatilité relativement proches, bien qu'AAPL reste légèrement plus volatile.\n",
        "\n",
        "Ces analyses permettent de mieux comprendre les dynamiques des actions AAPL, MSFT et GOOGL, notamment en termes de corrélations, de volumes échangés, de prix moyens et de volatilité, fournissant ainsi une base solide pour des décisions d'investissement.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE4MR_heH_Uq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
